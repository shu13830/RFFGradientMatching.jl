"""
Gaussian Process regression with inducing points.
"""
mutable struct GP
    z::Vector{Float64}               # inducing time points
    u::Vector{Float64}               # latent states at inducing time points
    x::Vector{Float64}               # training time points
    y::Vector{Float64}               # observations at training time points
    y_mean::Float64                  # mean of the observations
    y_std::Float64                   # std of the observations
    y_standardized::Vector{Float64}  # standardized observations
    Ïƒáµ¤::Float64                      # state noise std
    Ïƒ::Float64                       # observation noise std
    tÏƒ::PriorTransformation          # transform for Ïƒ
    k::KernelFunctions.Kernel        # kernel
    tÏ•::Vector{PriorTransformation}  # transforms for the kernel parameters
    f::AbstractGPs.GP                # f = GP(k)
    fz::AbstractGPs.FiniteGP         # fz = f(z)
    fâ€²::AbstractGPs.PosteriorGP      # fâ€² = posterior(fz, u)
    fâ€²x::AbstractGPs.FiniteGP        # fâ€²x = fâ€²(x)
    K::Matrix{Float64}               # kernel matrix
    Kâ»Â¹::Matrix{Float64}             # inverse of the kernel matrix
    Káµ€Kâ»Â¹::Matrix{Float64}           # K' * inv(K+Ïƒáµ¤Â²I)
    KÌ‚::Matrix{Float64}               # kernel matrix for posterior predictive
    L::Matrix{Float64}               # Cholesky decomposition of the kernel matrix
    Lâ»Â¹::Matrix{Float64}             # inverse of the Cholesky decomposition of the kernel matrix
    Kâ€²::Matrix{Float64}              # first derivative of the kernel with respect to the input 
    Kâ€³::Matrix{Float64}              # second derivative of the kernel with respect to the input
    Kâ€²áµ€Kâ»Â¹::Matrix{Float64}          # Kâ€²' * inv(K)
    standardize::Bool                # whether to standardize the observations
    centralize::Bool                 # whether to centralize the observations

    function GP(
        z::Vector{Float64},
        u::Vector{Float64},
        x::Vector{Float64},
        y::Vector{Float64},
        Ïƒáµ¤::Float64,
        Ïƒ::Float64;
        k::KernelFunctions.Kernel,
        standardize::Bool=false,
        centralize::Bool=false
    )
        tÏƒ = PriorTransformation(Normal(0, 1), log)
        Ï• = only_params(k)
        tÏ• = [PriorTransformation(Normal(0, 1), log) for (i, Ï•i) in enumerate(Ï•)]
        # GP prior
        f = AbstractGPs.GP(k)
        fz = f(z, Ïƒáµ¤^2)
        fâ€² = AbstractGPs.posterior(fz, u)
        fâ€²x = fâ€²(x, Ïƒ^2)
        K = cov(fz)
        Kâ»Â¹ = inv(K)
        Káµ€Kâ»Â¹ = KernelFunctions.kernelmatrix(k, x, z) * Kâ»Â¹
        KÌ‚ = KernelFunctions.kernelmatrix(k, x, x) - Káµ€Kâ»Â¹ * KernelFunctions.kernelmatrix(k, z, x)
        # NOTE: if x contains same points as z, 
        # diag(KÌ‚) may have negative values due to numerical errors.
        # Such elements are replaced with 1e-10 to make KÌ‚ positive semi-definite.
        KÌ‚[diagind(KÌ‚)] .= max.(diag(KÌ‚), 0) .+ 1e-10 
        
        L = cholesky(K).L
        Lâ»Â¹ = inv(L)
        Kâ€² = eval_dKdt(k, Ïƒáµ¤, z)
        Kâ€³ = eval_dÂ²KdtÂ²(k, Ïƒáµ¤, z)
        Kâ€²áµ€Kâ»Â¹ = Kâ€²' * Kâ»Â¹

        if standardize
            y_mean = StatsBase.mean(y)
            y_std = StatsBase.std(y)
            y_standardized = (y .- y_mean) ./ y_std
        elseif centralize
            y_mean = StatsBase.mean(y)
            y_std = 1.0
            y_standardized = y .- y_mean
        else
            y_mean = 0.0
            y_std = 1.0
            y_standardized = y
        end

        return new(z, u, x, y, y_mean, y_std, y_standardized, Ïƒáµ¤, Ïƒ, tÏƒ, k, 
            tÏ•, f, fz, fâ€², fâ€²x, K, Kâ»Â¹, Káµ€Kâ»Â¹, KÌ‚, L, Lâ»Â¹, Kâ€², Kâ€³, Kâ€²áµ€Kâ»Â¹, standardize, centralize)
    end
end

function reconstruct_kernel(k::KernelFunctions.Kernel, Ï•::AbstractVector{<:Real})
    base_k, inner, outer = params(k)
    new_inner = Ï•[1:end-1]
    new_outer = Ï•[end]
    k_new = new_outer^2 * kernel_inner(base_k, new_inner)
    return k_new
end

kernel_inner(::SqExponentialKernel, inner::AbstractVector{<:Real}) = with_lengthscale(SqExponentialKernel(), inner[1])
kernel_inner(::Matern52Kernel, inner::AbstractVector{<:Real}) = with_lengthscale(Matern52Kernel(), inner[1])
kernel_inner(::SigmoidKernel, inner::AbstractVector{<:Real}) = SigmoidKernel(inner...)

function reconstruct_gp(gp::GP;
    Ï•::Union{Nothing,AbstractVector{<:Real}}=nothing,
    u::Union{Nothing,AbstractVector{<:Real}}=nothing,
    Ïƒ::Union{Nothing,Float64}=nothing
)
    _Ï• = isnothing(Ï•) ? only_params(gp.k) : Ï•
    _u = isnothing(u) ? gp.u : u
    _Ïƒ = isnothing(Ïƒ) ? gp.Ïƒ : Ïƒ

    if isnothing(Ï•) && isnothing(u) && !isnothing(Ïƒ)
        gp.Ïƒ = _Ïƒ
        gp.fâ€²x = gp.fâ€²(gp.x, gp.Ïƒ^2)
    elseif isnothing(Ï•) && !isnothing(u)
        gp.fâ€² = AbstractGPs.posterior(gp.fz, _u)
        gp.Ïƒ = _Ïƒ
        gp.fâ€²x = gp.fâ€²(gp.x, gp.Ïƒ^2)
    elseif !isnothing(Ï•)
        gp = GP(gp.z, _u, gp.x, gp.y, gp.Ïƒáµ¤, _Ïƒ;
            k=reconstruct_kernel(gp.k, _Ï•), 
            standardize=gp.standardize, 
            centralize=gp.centralize)
    else
        @error "There is no update in the GP."
    end
    return gp
end

function reconstruct_gp(gp::Vector{GP}; Ï•::AbstractMatrix{<:Real})
    gp_reconstructed = GP[]
    for (gpk, Ï•k) in zip(gp, eachcol(Ï•))
        push!(gp_reconstructed, reconstruct_gp(gpk, Ï•=Ï•k[:]))
    end
    return gp_reconstructed
end

function f_conditional(f::AbstractGPs.GP, z::AbstractVector{<:Real}, u::AbstractVector{<:Real})
    fz = f(z, 1e-6)
    fâ€² = AbstractGPs.posterior(fz, u)
    return fâ€²
end

function update_u!(gp::GP, u::AbstractVector{<:Real})
    @assert length(u) == length(gp.z)
    gp.u[:] = u
    gp.fâ€² = AbstractGPs.posterior(gp.fz, u)
end

function update_y!(gp::GP, y::Vector{Float64})
    @assert length(y) == length(gp.x)
    gp.y[:] = y
    if gp.standardize
        gp.y_mean = StatsBase.mean(y)
        gp.y_std = StatsBase.std(y)
    elseif gp.centralize
        gp.y_mean = StatsBase.mean(y)
        gp.y_std = 1.0
    else
        gp.y_mean = 0.0
        gp.y_std = 1.0
    end
    gp.y_standardized = (y .- gp.y_mean) ./ gp.y_std
end

function calc_y_mean_and_diagcov(gp::GP, x::AbstractVector{<:Real}, Ïƒ::Real)
    if gp.z == gp.x  # in case where inducing points are the same as training points
        y_mean = x
        y_cov = Diagonal(Ïƒ^2 * ones(length(x)))
    else  # in case where inducing points are different from training points
        y_mean = gp.Káµ€Kâ»Â¹ * x
        y_cov = Diagonal(gp.KÌ‚) + Ïƒ^2 * LinearAlgebra.I
    end
    return y_mean, y_cov
end

# predict the mean and variance of the GP at the given time points
f_predictive(gp::GP, t_test::AbstractVector{<:Real}, sd::Float64) = gp.fâ€²(t_test, sd)

" cross-covariances between the kth state and its derivative"
function eval_dKdt(
    k::Tk, inner::Union{Float64,Tuple{Float64,Float64}}, outer::Float64, Ïƒ::Float64, t::AbstractVector{<:Real}
) where {Tk<:Union{SqExponentialKernel, Matern52Kernel, SigmoidKernel}}
    function _dkttâ€²_dt(k::SqExponentialKernel, ğ“::Float64, Î±::Float64, Ïƒ::Float64)
        _k = Î±^2 * with_lengthscale(k, ğ“) + Ïƒ^2 * WhiteKernel()
        dkdt = (t, tâ€²) -> ForwardDiff.derivative(t -> _k(t, tâ€²), t)
        dkdt
    end
    function _dkttâ€²_dt(k::Matern52Kernel, ğ“::Float64, Î±::Float64, Ïƒ::Float64)
        function __dkttâ€²_dt(t::Float64, tâ€²::Float64)
            r = abs(t - tâ€²)
            dk_dr = -Î±^2 * 5/3/ğ“^2*(t-tâ€²) * (1+âˆš5*r/ğ“) * exp(-âˆš5*r/ğ“)
            dk_dr
        end
        dkdt = (t, tâ€²) -> __dkttâ€²_dt(t, tâ€²)
        dkdt
    end
    function _dkttâ€²_dt(k::SigmoidKernel, inner::Tuple{Float64,Float64}, Î±::Float64, Ïƒ::Float64)
        b, a = inner
        _k = Î±^2 * SigmoidKernel(b, a) + Ïƒ^2 * WhiteKernel()
        dkdt = (t, tâ€²) -> ForwardDiff.derivative(t -> _k(t, tâ€²), t)
        dkdt
    end

    dkttâ€²_dt = _dkttâ€²_dt(k, inner, outer, Ïƒ)
    dKdt = [dkttâ€²_dt(t_i, t_j) for t_j in t, t_i in t]  # matrix
    return dKdt
end

eval_dKdt(
    k::KernelFunctions.Kernel, inner::Union{Float64,Tuple{Float64,Float64}}, outer::Float64, Ïƒ::Float64, t::AbstractVector{<:Real}
) = error("Only support SqExponentialKernel, Matern52Kernel and SigmoidKernel. Not implemented for kernel:\n$k.")

function eval_dKdt(k::KernelFunctions.Kernel, noise_std::Float64, t::AbstractVector{<:Real})
    _k, inner, outer = params(k)
    return eval_dKdt(_k, inner, outer, noise_std, t)
end

"the auto-covariance for each state derivative"
function eval_dÂ²KdtÂ²(
    k::Tk, inner::Union{Float64,Tuple{Float64,Float64}}, outer::Float64, Ïƒ::Float64, t::AbstractVector{<:Real}
) where {Tk<:Union{SqExponentialKernel, Matern52Kernel, SigmoidKernel}}
    function _dÂ²kttâ€²_dtdtâ€²(k::SqExponentialKernel, ğ“::Float64, Î±::Float64, Ïƒ::Float64)
        k = Î±^2 * with_lengthscale(k, ğ“) + Ïƒ^2 * WhiteKernel()
        d2k_dtdtâ€² = (t, tâ€²) -> ForwardDiff.derivative(Î¾ -> ForwardDiff.derivative(Î· -> k(Î¾, Î·), tâ€²), t)
    end
    function _dÂ²kttâ€²_dtdtâ€²(k::Matern52Kernel, ğ“::Float64, Î±::Float64, Ïƒ::Float64)
        function __dÂ²kttâ€²_dtdtâ€²(t::Float64, tâ€²::Float64)
            r = abs(t - tâ€²)
            d2k_dr2 = Î±^2 * 5/3/ğ“^2 * (1 + âˆš5*r/ğ“ - 5*r^2/ğ“^2) * exp(-âˆš5*r/ğ“)
            d2k_dr2
        end
        d2k_dtdtâ€² = (t, tâ€²) -> __dÂ²kttâ€²_dtdtâ€²(t, tâ€²)
    end
    function _dÂ²kttâ€²_dtdtâ€²(k::SigmoidKernel, inner::Tuple{Float64,Float64}, Î±::Float64, Ïƒ::Float64)
        b, a = inner
        k = Î±^2 * SigmoidKernel(b, a) + Ïƒ^2 * WhiteKernel()
        d2k_dtdtâ€² = (t, tâ€²) -> ForwardDiff.derivative(Î¾ -> ForwardDiff.derivative(Î· -> k(Î¾, Î·), tâ€²), t)
    end
    
    dÂ²kttâ€²_dtdtâ€² = _dÂ²kttâ€²_dtdtâ€²(k, inner, outer, Ïƒ)
    dÂ²KdtÂ² = [dÂ²kttâ€²_dtdtâ€²(t_i, t_j) for t_j in t, t_i in t]  # matrix
    return dÂ²KdtÂ²
end

eval_dÂ²KdtÂ²(
    k::KernelFunctions.Kernel, inner::Union{Float64,Tuple{Float64,Float64}}, outer::Float64, Ïƒ::Float64, x::AbstractVector{<:Real}
) = error("Only support SqExponentialKernel, Matern52Kernel and SigmoidKernel. Not implemented for kernel:\n$k.")

function eval_dÂ²KdtÂ²(k::KernelFunctions.Kernel, noise_std::Float64, t::AbstractVector{<:Real})
    _k, inner, outer = params(k)
    return eval_dÂ²KdtÂ²(_k, inner, outer, noise_std, t)
end

eval_dKdÎ±(k::SqExponentialKernel, ğ“::Float64, Î±::Float64, Ïƒ::Float64, t::AbstractVector{<:Real}) = error("Not implemented")
eval_dKdÎ±(k::Matern52Kernel, ğ“::Float64, Î±::Float64, Ïƒ::Float64, t::AbstractVector{<:Real}) = error("Not implemented")
eval_dKdÎ±(k::SigmoidKernel, b::Float64, a::Float64, Î±::Float64, Ïƒ::Float64, t::AbstractVector{<:Real}) = error("Not implemented")

eval_dKdğ“(k::SqExponentialKernel, ğ“::Float64, Î±::Float64, Ïƒ::Float64, t::AbstractVector{<:Real}) = error("Not implemented")
eval_dKdğ“(k::Matern52Kernel, ğ“::Float64, Î±::Float64, Ïƒ::Float64, t::AbstractVector{<:Real}) = error("Not implemented")

eval_dKdb(k::SigmoidKernel, b::Float64, a::Float64, Î±::Float64, Ïƒ::Float64, t::AbstractVector{<:Real}) = error("Not implemented")
eval_dKda(k::SigmoidKernel, b::Float64, a::Float64, Î±::Float64, Ïƒ::Float64, t::AbstractVector{<:Real}) = error("Not implemented")

function params(k::KernelFunctions.ScaledKernel)
    ÏƒÂ² = only(k.ÏƒÂ²)
    _k, inner, outer = params(k.kernel)
    return _k, inner, outer * âˆšÏƒÂ²
end
function params(k::KernelFunctions.TransformedKernel)
    s = only(k.transform.s)
    _k, inner, outer = params(k.kernel)
    return _k, inner / s, outer
end
params(::SqExponentialKernel) = (SqExponentialKernel(), 1.0, 1.0)
params(::Matern52Kernel) = (Matern52Kernel(), 1.0, 1.0)
params(k::SigmoidKernel) = (SigmoidKernel(), (k.b, k.a), 1.0)
params(::KernelFunctions.Kernel) = error("Not implemented for kernel:\n$k")

only_params(k::KernelFunctions.ScaledKernel) = params(k)[2:end] |> collect
only_params(k::KernelFunctions.TransformedKernel) = params(k)[2:end] |> collect
only_params(k::KernelFunctions.Kernel) = error("Not implemented for kernel:\n$k")
only_params(::SqExponentialKernel) = params(SqExponentialKernel())[2:end] |> collect
only_params(::Matern52Kernel) = params(Matern52Kernel())[2:end] |> collect
only_params(::SigmoidKernel) = params(SigmoidKernel())[2:end] |> collect

cov_inducing(gp::GP) = cov(gp.fz)

# gradient of the GP function
dfdt_mean(gp::GP, x::AbstractVector{<:Real}) = gp.Kâ€²áµ€Kâ»Â¹ * x
dfdt_mean(gp::GP) = dfdt_mean(gp, gp.u)
dfdt_mean(gp::Vector{GP}, X::AbstractMatrix{<:Real}) = [dfdt_mean(gp[k], xk[:]) for (k, xk) in enumerate(eachrow(X))]

dfdt_cov(gp::GP) = gp.Kâ€³ - gp.Kâ€²' * (cov(gp.fz) \ gp.Kâ€²)
dfdt_cov(gp::Vector{GP}) = [dfdt_cov(gp[i]) for i in 1:length(gp)]

# logpdf functions
logpdf_f(gp::GP) = logpdf(gp.fz, gp.u)
logpdf_fâ€²(gp::GP, t::AbstractVector{<:Real}, y::AbstractVector{<:Real}, sd::Float64) = logpdf(f_predictive(gp, t, sd), y)  #TODO

# derivatives of the logpdf functions
# gradlogpdf_f(gp::GP) = gradlogpdf(rgp.fâ€²(RowVecs(t[:,:]), sd), y)  # TODO
# gradlogpdf_f(gp::GP) = gradlogpdf(rgp.fâ€²(RowVecs(t[:,:]), sd), y)  # TODO
# gradlogpdf_fâ€²_w(rgp::RFFGP, t::AbstractVector{<:Real}, y::AbstractVector{<:Real}, sd::Float64) = gradlogpdf(rgp.fâ€²(RowVecs(t[:,:]), sd), y)  # TODO

function plot(gp::GP)
    times = gp.z
    diff_t = times[end]-times[1]
    t_test = collect((times[1]-diff_t/20):diff_t/100:(times[end]+diff_t/20))
    Plots.plot(gp.fâ€²(t_test, gp.Ïƒ), ribbon_scale=3, label="f(t)", xlabel="t")
    Plots.scatter!(gp.z, gp.u, c=:blue, label="x")
    Plots.scatter!(gp.z, gp.y, c=:red, label="y")
    Plots.title!("GP regression")
end

function plot_graddist(gp::GP)
    grad_mean = dfdt_mean(gp)
    Ïƒ_vec = sqrt.(diag(dfdt_cov(gp)))
    upper = grad_mean .+ 3 * Ïƒ_vec
    lower = grad_mean .- 3 * Ïƒ_vec
    Plots.scatter(gp.z, grad_mean, c=:blue, label="ğ”¼[df/dt]", ms=1, xlabel="t")
    Plots.bar!(gp.z, upper, fillrange=lower, fillalpha=0.5, label="Â±3Ïƒ", c=:lightblue)
    Plots.hline!([0], c=:black, label="", ls=:dash)
    Plots.title!("Gradient distribution of GP")
end

function plot_gradcov(gp::GP; clims=(-1., 1.))
    grad_cov = dfdt_cov(gp)
    mid = sum(clims) / 2
    Plots.heatmap(
        grad_cov, y_flip=true, clims=clims,
        c=cgrad([:blue, :white, :red], [clims[1], mid, clims[2]]))
    Plots.title!("Cov[df/dt, df/dt] in GP")
end
