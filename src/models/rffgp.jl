"""
Random Fourier Features-based Gaussian Process regression with inducing points.
"""
mutable struct RFFGP
    z::Vector{Float64}               # inducing time points
    u::Vector{Float64}               # latent states at inducing time points
    x::Vector{Float64}               # training time points
    y::Vector{Float64}               # observations at training time points
    y_mean::Float64                  # mean of the observations
    y_std::Float64                   # std of the observations
    y_standardized::Vector{Float64}  # standardized observations
    Ïƒáµ¤::Float64                      # state noise std
    Ïƒ::Float64                       # observation noise std
    tÏƒ::PriorTransformation          # prior transform for Ïƒ
    k::KernelFunctions.Kernel        # kernel
    n_rff::Int                       # number of random fourier features
    h::RFFBasis                      # random fourier features
    tÏ•::Vector{PriorTransformation}  # prior transforms for the kernel parameters
    blr::BayesianLinearRegressor     # Bayesian linear regressor
    f::BasisFunctionRegressor        # f = BasisFunctionRegressor(blr, h)
    fz::AbstractGPs.FiniteGP         # fz = f(z)
    fâ€²::BasisFunctionRegressor       # fâ€² = posterior(fz, u)
    fâ€²x::AbstractGPs.FiniteGP        # fâ€²x = fâ€²(x)
    H::Matrix{Float64}               # random fourier features at inducing points
    Hâ€²::Matrix{Float64}              # random fourier features at training points
    w::Vector{Float64}               # weights of random fourier features
    dHdt::Matrix{Float64}            # gradient of the random fourier features with respect to the input (rows: n_rff, cols: length(z)) 
    standardize::Bool                # whether to standardize the observations
    centralize::Bool                 # whether to centralize the observations

    function RFFGP(
        z::Vector{Float64},
        u::Vector{Float64},
        x::Vector{Float64},
        y::Vector{Float64},
        Ïƒáµ¤::Float64,
        Ïƒ::Float64;
        k::KernelFunctions.Kernel,
        n_rff::Int=100,
        standardize::Bool=false,
        centralize::Bool=false
    )

        # Default prior and transform for Ïƒ. User can change them by calling `set_priortransform_on_Ïƒ!``
        tÏƒ = PriorTransformation(Normal(0, 1), log)
        
        # Build RFF basis (supports both standard and generalized kernels via compat.jl)
        input_dims = 1  # input dimension is only time here
        h = build_rff_basis(k, input_dims, n_rff)
        tÏ• = [PriorTransformation(Normal(0, 1), log) for (i, Ï•i) in enumerate(only_params(k))]

        # construct an approximated GP with random Fourier features
        prior_mw = FillArrays.Zeros(n_rff)  # prior weight mean
        prior_Î›w = Diagonal(FillArrays.Ones(n_rff))  # prior weight precision
        blr = BayesianLinearRegressor(prior_mw, prior_Î›w)
        f = BasisFunctionRegressor(blr, h)
        fz = f(RowVecs(z[:,:]), Ïƒáµ¤^2)
        fâ€² = BayesianLinearRegressors.posterior(fz, u)
        fâ€²x = fâ€²(RowVecs(x[:,:]), Ïƒ^2)
        H = h(RowVecs(z[:,:])).X
        Hâ€² = h(RowVecs(x[:,:])).X
        w = fâ€².blr.mw
        dHdt = eval_dHdt(h, z)

        if standardize
            y_mean = StatsBase.mean(y)
            y_std = StatsBase.std(y)
            y_standardized = (y .- y_mean) ./ y_std
        elseif centralize
            y_mean = StatsBase.mean(y)
            y_std = 1.0
            y_standardized = y .- y_mean
        else
            y_mean = 0.0
            y_std = 1.0
            y_standardized = y
        end

        return new(z, u, x, y, y_mean, y_std, y_standardized, Ïƒáµ¤, Ïƒ, tÏƒ, k, 
            n_rff, h, tÏ•, blr, f, fz, fâ€², fâ€²x, H, Hâ€², w, dHdt, standardize, centralize)
    end
end

function reconstruct_gp(gp::RFFGP;
    Ï•::Union{Nothing,Vector{Float64}}=nothing,
    u::Union{Nothing,Vector{Float64}}=nothing,
    Ïƒ::Union{Nothing,Float64}=nothing
)
    _Ï• = isnothing(Ï•) ? only_params(gp.k) : Ï•
    _u = isnothing(u) ? gp.u : u
    _Ïƒ = isnothing(Ïƒ) ? gp.Ïƒ : Ïƒ

    if isnothing(Ï•) && isnothing(u) && !isnothing(Ïƒ)
        gp.Ïƒ = _Ïƒ
        gp.fâ€²x = gp.fâ€²(RowVecs(gp.x[:,:]), gp.Ïƒ^2)
    elseif isnothing(Ï•) && !isnothing(u)
        gp.fâ€² = BayesianLinearRegressors.posterior(gp.fz, _u)
        gp.Ïƒ = _Ïƒ
        gp.fâ€²x = gp.fâ€²(RowVecs(gp.x[:,:]), gp.Ïƒ^2)
        gp.w = gp.fâ€².blr.mw
    elseif !isnothing(Ï•)
        gp = RFFGP(gp.z, _u, gp.x, gp.y, gp.Ïƒáµ¤, _Ïƒ;
            k=reconstruct_kernel(gp.k, _Ï•), 
            n_rff=gp.n_rff, 
            standardize=gp.standardize, 
            centralize=gp.centralize)
    else
        @error "There is no update in the GP."
    end
    return gp
end

function reconstruct_gp(gp::Vector{RFFGP}; Ï•::AbstractMatrix{<:Real})
    gp_reconstructed = RFFGP[]
    for (gpk, Ï•k) in zip(gp, eachcol(Ï•))
        push!(gp_reconstructed, reconstruct_gp(gpk, Ï•=Ï•k[:]))
    end
    return gp_reconstructed
end

function set_Ïƒ_prior!(gp::RFFGP, pÏƒ::Distribution)
    gp.pÏƒ = pÏƒ
end

function f_conditional(f::BasisFunctionRegressor, z::AbstractVector{<:Real}, u::AbstractVector{<:Real})
    fz = f(RowVecs(z[:,:]), 1e-6)
    fâ€² = BayesianLinearRegressors.posterior(fz, u)
    return fâ€²
end

function update_u!(gp::RFFGP, u::Vector{Float64})
    @assert length(u) == length(gp.z)
    gp.u[:] = u
    gp.fâ€² = BayesianLinearRegressors.posterior(gp.fz, u)
end

function update_y!(gp::RFFGP, y::Vector{Float64})
    @assert length(y) == length(gp.x)
    gp.y[:] = y
    if gp.standardize
        gp.y_mean = StatsBase.mean(y)
        gp.y_std = StatsBase.std(y)
    elseif gp.centralize
        gp.y_mean = StatsBase.mean(y)
        gp.y_std = 1.0
    else
        gp.y_mean = 0.0
        gp.y_std = 1.0
    end
    gp.y_standardized = (y .- gp.y_mean) ./ gp.y_std
end

weight_mean(gp::RFFGP) = gp.fâ€².blr.mw  # == Î›wâ»Â¹/Ïƒáµ¤Â² * Î¦áµ€x
weight_mean(gp::Vector{RFFGP}) = [weight_mean(gpk) for gpk in gp]
weight_mean_matrix(gp::Vector{RFFGP}) = reduce(vcat, weight_mean(gp)')
weight_precision(gp::RFFGP) = gp.fâ€².blr.Î›w  # == (Î±Â²I + Î¦áµ€Î¦/Ïƒáµ¤Â²)
noise_cov(gp::RFFGP) = gp.fz.Î£y  # == Î£x = Ïƒáµ¤Â²I
dHdt(gp::RFFGP) = gp.dHdt  # == âˆ‚H/âˆ‚t
Hmat(gp::RFFGP, t::AbstractVector{<:Real}) = gp.h(RowVecs(t[:,:])).X  # == H
Hmat(gp::RFFGP) = Hmat(gp, gp.z)

# predict the mean and variance of the GP at the given time points
f_predictive(gp::RFFGP, t_test::AbstractVector{<:Real}, sd::Float64) = gp.fâ€²(RowVecs(t_test[:,:]), sd)

# gradient of the GP function
# numerical_dHdt = t -> ForwardDiff.jacobian(_t -> h(RowVecs(_t)).X, t)
# eval_dHdt(h, t) â‰ˆ numerical_dHdt(t)
function eval_dHdt(h::RFFBasis, t::AbstractVector{<:Real})
    ð“ = h.inner_weights
    outer_scaled = h.outer_weights  # âˆš(2 * Î±^2 / n_rff)
    _t = t ./ ð“
    return (outer_scaled * h.Ï‰ ./ ð“ .* -sin.(h.Ï‰ .* _t .+ h.Ï„'))' |> Matrix
end

function eval_dhdÎ±(h::RFFBasis, t::AbstractVector{<:Real}, Î±::AbstractVector{<:Real})
    ð“ = h.inner_weights
    _t = t ./ ð“
    n_rff = length(h.Ï‰)
    return âˆš(2 / n_rff) .* cos.(h.Ï‰ .* _t .+ h.Ï„')
end  # TODO

function eval_dhdð“(h::RFFBasis, t::AbstractVector{<:Real}, ð“::AbstractVector{<:Real})
    ð“ = h.inner_weights
    outer_scaled = h.outer_weights  # âˆš(2 * Î±^2 / n_rff)
    _t = t ./ ð“
    return outer_scaled .* (h.Ï‰ .* _t) ./ ð“^2 .* sin.(h.Ï‰ .* _t .+ h.Ï„')
end  # TODO

mean(gp::RFFGP, w::AbstractVector{<:Real}, t::AbstractVector{<:Real}) = Hmat(gp, t) * w
mean(gp::RFFGP) = mean(gp, gp.w, gp.z)
mean(gp::Vector{RFFGP}, W::AbstractMatrix{<:Real}) = [mean(gpk, wk[:], gpk.z) for (gpk, wk) in zip(gp, eachrow(W))]
mean(gp::Vector{RFFGP}, t::AbstractVector{<:Real}) = [mean(gpk, gpk.w, t) for gpk in gp]
W2X(gp::Vector{RFFGP}, W::AbstractMatrix{<:Real}) = reduce(vcat, mean(gp, W)')
t2X(gp::Vector{RFFGP}, t::AbstractVector{<:Real}) = reduce(vcat, mean(gp, t)')
Wt2X(gp::Vector{RFFGP}, W::AbstractMatrix{<:Real}, t::AbstractVector{<:Real}) = reduce(vcat, mean(gp, W, t)')

function calc_y_mean_and_diagcov(gp::RFFGP, w::AbstractVector{<:Real}, Ïƒ::Real)
    y_mean = gp.Hâ€² * w
    y_cov = Diagonal(Ïƒ^2 * ones(length(gp.y_standardized)))
    return y_mean, y_cov
end

dfdt_mean(gp::RFFGP, w::AbstractVector{<:Real}) = gp.dHdt' * w
dfdt_mean(gp::RFFGP) = dfdt_mean(gp, gp.w)
dfdt_mean(gp::Vector{RFFGP}, W::AbstractMatrix{<:Real}) = [dfdt_mean(gp[k], wk[:]) for (k, wk) in enumerate(eachrow(W))]

dfdt_cov(gp::RFFGP) = gp.dHdt' * (weight_precision(gp) \ gp.dHdt)
dfdt_cov(gp::Vector{RFFGP}) = [dfdt_cov(gpk) for gpk in gp]

# logpdf functions
logpdf_w(gp::RFFGP) = sum(logpdf.(Normal(0, 1), gp.fâ€².blr.mw))  # TODO
logpdf_f(gp::RFFGP) = logpdf(gp.fz, gp.y)  # TODO
logpdf_fâ€²(gp::RFFGP, t::AbstractVector{<:Real}, y::AbstractVector{<:Real}, sd::Float64) = logpdf(gp.fâ€²(RowVecs(t[:,:]), sd), y)  # TODO

# derivatives of the logpdf functions
âˆ‡w_logpdf_f(gp::RFFGP) = gradlogpdf(gp.fâ€²(RowVecs(gp.z[:,:]), gp.Ïƒ), gp.y)  # TODO
âˆ‡w_logpdf_fâ€²(gp::RFFGP, t::AbstractVector{<:Real}, y::AbstractVector{<:Real}, sd::Float64) =
    gradlogpdf(gp.fâ€²(RowVecs(t[:,:]), sd), y)  # TODO

function plot(gp::RFFGP)
    times = gp.z
    diff_t = times[end]-times[1]
    t_test = collect((times[1]-diff_t/20):diff_t/100:(times[end]+diff_t/20))
    Plots.plot(t_test, gp.fâ€²(RowVecs(t_test[:,:]), gp.Ïƒ), ribbon_scale=3, label="f(t)", xlabel="t")
    Plots.scatter!(gp.z, gp.u, c=:blue, label="x")
    Plots.scatter!(gp.z, gp.y, c=:red, label="y")
    Plots.title!("RFF-GP regression")
end

function plot_graddist(gp::RFFGP)
    grad_mean = dfdt_mean(gp)
    Ïƒ_vec = sqrt.(diag(dfdt_cov(gp)))
    upper = grad_mean .+ 3 * Ïƒ_vec
    lower = grad_mean .- 3 * Ïƒ_vec
    Plots.scatter(gp.z, grad_mean, c=:blue, label="ð”¼[df/dt]", ms=1, xlabel="t")
    Plots.bar!(gp.z, upper, fillrange=lower, fillalpha=0.5, label="Â±3Ïƒ", c=:lightblue)
    Plots.hline!([0], c=:black, label="", ls=:dash)
    Plots.title!("Gradient distribution of RFF-GP")
end

function plot_gradcov(gp::RFFGP; clims=(-1., 1.))
    grad_cov = dfdt_cov(gp)
    mid = sum(clims) / 2
    Plots.heatmap(
        grad_cov, y_flip=true, clims=clims,
        c=cgrad([:blue, :white, :red], [clims[1], 0, clims[2]]))
    Plots.title!("Cov[df/dt, df/dt] in RFF-GP")
end

function compare_gradcovelms(gp::GP, rgp::RFFGP)
    gradcov_gp = dfdt_cov(gp)
    gradcov_rgp = dfdt_cov(rgp)
    elm_gradcov_gp = vcat(eachcol(gradcov_gp)...)
    elm_gradcov_rgp = vcat(eachcol(gradcov_rgp)...)

    scatter(
        elm_gradcov_gp, elm_gradcov_rgp,
        label=false,
        xlabel="Cov[df/dt]_i,j in GP",
        ylabel="Cov[df/dt]_i,j in RFF-GP",
    )
    plot!(-1:0.1:1, -1:0.1:1, label=false, ls=:dash, c=:black)
end
